# HybridGait

<!-- Project Page | Video | Paper | Data -->

<!-- ![Reconstructed Objects](path_to_images) -->

HybridGait: A Benchmark for Spatial-Temporal Cloth-Changing Gait Recognition with Hybrid Explorations
Authors: Yilan Dong,Chunlin Yu,Ruiyang Ha,Ye Shi,Yuexin Ma,Lan Xu,Yanwei Fu,Jingya Wang
Conference: Association for the Advancement of Artificial Intelligence(AAAI), 2024

<!-- ## Updates

- 2023/06/19: The hand tracking code is released here: [EasyMocap](link_to_EasyMocap)
- 2023/02/13: For people who do not want to run hand tracking, we provide the processed hand tracking results: [HOD_S1_HT](link) and [HOD_D1_HT](link).  -->

## TODO List

- [ ] Release the dataset.

## Installation

### Set up the environment
'git clone https://github.com/HCVLab/HybridGait.git'
'conda create -n HybridGait python=3.7'
'conda activate HybridGait'
'pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111  -f https://download.pytorch.org/whl/torch_stable.html'
'cd HybridGait'
'pip install -r requirement.txt'


